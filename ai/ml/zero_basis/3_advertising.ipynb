{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Online store advertising\n",
    "\n",
    "## 1. Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "DF_ads = pd.read_csv(\"./dataset/3_2_advertising.csv\")\n",
    "# DF_ads\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Analyze to data\n",
    "\n",
    "use methods of data visualiaztion to deduce the most relation feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns  # A data-visualization tool of Seaborn of Statistics\n",
    "\n",
    "\"draw heatmap(热力图) to all label and features\"\n",
    "sns.heatmap(DF_ads.corr(), cmap=sns.cm._flare_lut, annot=True)\n",
    "plt.show()\n",
    "\n",
    "\"use scatter to dispaly relation of 2(ads method and sale)\"\n",
    "sns.pairplot(DF_ads,\n",
    "             x_vars=['wechat', 'weibo', 'others'],\n",
    "             y_vars='sales',\n",
    "             height=4, aspect=1, kind='scatter')\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Clean and format of dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"as we know the 'wecaht' are most corelate feature to the label from upon seies\"\n",
    "X = np.array(DF_ads.wechat)\n",
    "y = np.array(DF_ads.sales)\n",
    "print(\"rank of X: \", X.ndim)\n",
    "print(\"shape of X: \", X.shape)\n",
    "print(X)\n",
    "\n",
    "\"format to 2D tensor, so that ml model can received\"\n",
    "X = X.reshape((len(X), 1))\n",
    "y = y.reshape((len(y), 1))\n",
    "print(\"rank of X: \", X.ndim)\n",
    "print(\"shape of X: \", X.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have 2 dimension, 1 for sample(样本) (just meaning of 1 row), 1 for feature(特征) (the data or this row)\n",
    "\n",
    "Then we need to do is:\n",
    "  1. split dataset into train-set and test-set   \n",
    "\n",
    "  2. unifrom(归一化) to dataset like below function\n",
    "   \n",
    "      $$x^{'}=\\frac{x-min(x)}{max(X)-min(X)}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "print(X_train.shape, '---', X_train.ndim)\n",
    "print(y_train.shape, '---', y_train.ndim)\n",
    "\n",
    "\"user ourselves' unifrom method instead of MaxScaler of sklearn.preprocessing\"\n",
    "\n",
    "\n",
    "def scaler(train: np.array, test: np.array):\n",
    "    # max and min value of train-set\n",
    "    min = train.min(axis=0)\n",
    "    max = train.max(axis=0)\n",
    "    # diff of max and min\n",
    "    gap = max - min\n",
    "\n",
    "    \"all data substruct by min value, and then divide by diff of range(区间), and so on...\"\n",
    "    train -= min\n",
    "    train /= gap\n",
    "\n",
    "    test -= min\n",
    "    test /= gap\n",
    "\n",
    "    \"return datas that have been compressed\"\n",
    "    return train, test\n",
    "\n",
    "\n",
    "# function also equivalent to this, just equvalation above\n",
    "# x_norm = (x_data -np.min(x_data)) / np(max(x_data)-np.min(x_data)).values\n",
    "\n",
    "# NOTICE: cannot use diff(gap) by the max-min from `testset`!!! so will use the train-set's diff\n",
    "X_train, X_test = scaler(X_train, X_test)\n",
    "y_train, y_test = scaler(y_train, y_test)\n",
    "\n",
    "\n",
    "\"display datas that have beeb precessor\"\n",
    "plt.plot(X_train, y_train, 'r.', label=\"Trainning data\")\n",
    "plt.xlabel(\"wechat\")\n",
    "plt.ylabel('sales')\n",
    "plt.legend()  # display 图例-legend\n",
    "plt.show()\n",
    "# notice the `r` and `r.`\n",
    "plt.plot(X_train, y_train, 'r', label=\"Trainning data\")\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Choose model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
